## 所有机器配置 主要配置ip和hostname
## All the servers
[all_servers]
172.28.30.28 host_ip=172.28.30.28 host_name=b1
172.28.30.29 host_ip=172.28.30.29 host_name=b2
172.28.30.30 host_ip=172.28.30.30 host_name=b3

## TiDB 集群相关配置
## TiDB Cluster Part
[tidb_servers]
tidb1 ansible_host=172.28.30.28 deploy_dir=/data1/bigdata/tidb
tidb2 ansible_host=172.28.30.29 deploy_dir=/data1/bigdata/tidb
tidb3 ansible_host=172.28.30.30 deploy_dir=/data1/bigdata/tidb

[tikv_servers]
tikv1 ansible_host=172.28.30.28 deploy_dir=/data1/bigdata/tikv
tikv2 ansible_host=172.28.30.29 deploy_dir=/data1/bigdata/tikv
tikv3 ansible_host=172.28.30.30 deploy_dir=/data1/bigdata/tikv

#tikv1-1 ansible_host=172.28.30.28 deploy_dir=/data1/bigdata/tikv tikv_port=20171 tikv_status_port=20181 labels="host=tikv1-1"
#tikv1-2 ansible_host=172.28.30.28 deploy_dir=/data2/bigdata/tikv tikv_port=20172 tikv_status_port=20182 labels="host=tikv1-2"
#tikv2-1 ansible_host=172.28.30.29 deploy_dir=/data1/bigdata/tikv tikv_port=20171 tikv_status_port=20181 labels="host=tikv2-1"
#tikv2-2 ansible_host=172.28.30.29 deploy_dir=/data2/bigdata/tikv tikv_port=20172 tikv_status_port=20182 labels="host=tikv2-2"
#tikv3-1 ansible_host=172.28.30.30 deploy_dir=/data1/bigdata/tikv tikv_port=20171 tikv_status_port=20181 labels="host=tikv3-1"
#tikv3-2 ansible_host=172.28.30.30 deploy_dir=/data2/bigdata/tikv tikv_port=20172 tikv_status_port=20182 labels="host=tikv3-2"

[pd_servers]
tipd1 ansible_host=172.28.30.28 deploy_dir=/data1/bigdata/tipd
tipd2 ansible_host=172.28.30.29 deploy_dir=/data1/bigdata/tipd
tipd3 ansible_host=172.28.30.30 deploy_dir=/data1/bigdata/tipd

[spark_master]

[spark_slaves]

[lightning_server]

[importer_server]

## 大数据集群相关配置
## BigData Cluster Part
[hadoop_servers]
hadoop1 ansible_host=172.28.30.28 name=master deploy_dir=/data1/bigdata/hadoop
hadoop2 ansible_host=172.28.30.29 name=slave deploy_dir=/data1/bigdata/hadoop
hadoop3 ansible_host=172.28.30.30 deploy_dir=/data1/bigdata/hadoop

# hdfs
[namenode_servers]
172.28.30.28 name=master
172.28.30.29 name=slave

[datanode_servers]
172.28.30.28
172.28.30.29
172.28.30.30

# yarn
[resourcemanager_servers]
172.28.30.28
172.28.30.29

[nodemanager_servers]
172.28.30.28
172.28.30.29
172.28.30.30

[hive_servers]
hive1 ansible_host=172.28.30.28 deploy_dir=/data1/bigdata/hive

[spark_servers]
spark1 ansible_host=172.28.30.28 deploy_dir=/data1/bigdata/spark

[sqoop_servers]
sqoop1 ansible_host=172.28.30.28 deploy_dir=/data1/bigdata/sqoop

[zookeeper_servers]
zookeeper1 ansible_host=172.28.30.28 myid=1 deploy_dir=/data1/bigdata/zookeeper
zookeeper2 ansible_host=172.28.30.29 myid=2 deploy_dir=/data1/bigdata/zookeeper
zookeeper3 ansible_host=172.28.30.30 myid=3 deploy_dir=/data1/bigdata/zookeeper

## Ds Cluster Part
[ds_servers]
172.28.30.28 deploy_dir=/data1/bigdata/ds

[ds_api_log_alert]
ds1 ansible_host=172.28.30.28

[ds_masters]
ds_master1 ansible_host=172.28.30.28

[ds_workers]
ds_worker1 ansible_host=172.28.30.28

## Monitoring Part
# prometheus and pushgateway servers
[monitoring_servers]
172.28.30.28 deploy_dir=/data1/bigdata/monitoring

[grafana_servers]
172.28.30.28 deploy_dir=/data1/bigdata/monitoring

# node_exporter and blackbox_exporter servers
[monitored_servers]
172.28.30.28 deploy_dir=/data1/bigdata/monitoring
172.28.30.29 deploy_dir=/data1/bigdata/monitoring
172.28.30.30 deploy_dir=/data1/bigdata/monitoring

[alertmanager_servers]
172.28.30.28 deploy_dir=/data1/bigdata/monitoring

[kafka_exporter_servers]

## Binlog Part
[pump_servers]

[drainer_servers]

## Group variables
[pd_servers:vars]
# location_labels = ["zone","rack","host"]

## Global variables
[all:vars]
deploy_dir = /data1/bigdata
root_dir = /data1/bigdata

## Connection
# ssh via normal user and port
ansible_user = tidb
ansible_port = 22

cluster_name = mycluster

tidb_version = v3.0.15

# don't make him special
haproxy_version = 1.5.18

java_version = 1.8.0_261
scala_version = 2.12.12

zookeeper_version = 3.4.14
hadoop_version = 2.7.7
hive_version = 2.3.7
spark_version = 2.4.4
sqoop_version = 1.4.6

ds_version = 1.3.1

# process supervision, [systemd, supervise]
process_supervision = systemd

timezone = Asia/Shanghai

enable_firewalld = False
# check NTP service
enable_ntpd = True
set_hostname = False

## binlog trigger
enable_binlog = False

# kafka cluster address for monitoring, example:
# kafka_addrs = "192.168.0.11:9092,192.168.0.12:9092,192.168.0.13:9092"
kafka_addrs = ""

# zookeeper address of kafka cluster for monitoring, example:
# zookeeper_addrs = "192.168.0.11:2181,192.168.0.12:2181,192.168.0.13:2181"
zookeeper_addrs = ""

# enable TLS authentication in the TiDB cluster
enable_tls = False

# KV mode
deploy_without_tidb = False

# wait for region replication complete before start tidb-server.
wait_replication = True

# Optional: Set if you already have a alertmanager server.
# Format: alertmanager_host:alertmanager_port
alertmanager_target = ""

grafana_admin_user = "admin"
grafana_admin_password = "admin"


### Collect diagnosis
collect_log_recent_hours = 2

enable_bandwidth_limit = True
# default: 10Mb/s, unit: Kbit/s
collect_bandwidth_limit = 10000
